{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedeNeuralGanKeras",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1g5HG2Am3um9kArltuf1WjXdQINohv6s_",
      "authorship_tag": "ABX9TyN0XoxHUkKrQYZ/hhffCnQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helsonmatos/EstudosRN/blob/main/RedeNeuralGanKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YItuNVg0iKha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430c5b64-3eba-46a2-f061-fa50a000f702"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_treino,_),(_,_) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TmpV3BfjT6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cabc6d4-28ad-49cb-fd79-5483c1834050"
      },
      "source": [
        "x_treino.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T2zeS2RmspM"
      },
      "source": [
        "x_treino = x_treino / 127.5 - 1.0\n",
        "x_treino = np.expand_dims(x_treino, axis=3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZPtpLkim9KG",
        "outputId": "f9ec596e-d979-4d79-9742-2dc422bd9027"
      },
      "source": [
        "x_treino.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYuWQw_gnAXf"
      },
      "source": [
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        # input shape\n",
        "        self.altura = 28\n",
        "        self.largura = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.altura, self.largura, self.channels)\n",
        "        self.dimensao_randomica = 100\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "        #Definindo o discriminator:\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        #Definindo generator:\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        #Definindo o modelo completo:\n",
        "        esqueleto_entrada_randomica = Input(shape=(self.dimensao_randomica,))\n",
        "        esqueleto_imagem_gerada = self.generator(esqueleto_entrada_randomica)\n",
        "\n",
        "        self.discriminator.trainable = False # impedindo o discriminator de treinar\n",
        "        verificacoes = self.discriminator(esqueleto_imagem_gerada)\n",
        "\n",
        "        self.gan_completa = Model(esqueleto_entrada_randomica, verificacoes)\n",
        "        self.gan_completa.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        modelo = Sequential()\n",
        "\n",
        "        # O objeto é finalizar com uma dimensão 28 x 28 x 1:\n",
        "        modelo.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.dimensao_randomica))\n",
        "        modelo.add(Reshape((7, 7, 128)))\n",
        "        modelo.add(UpSampling2D())\n",
        "        modelo.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        modelo.add(BatchNormalization(momentum=0.8))\n",
        "        modelo.add(Activation(\"relu\"))\n",
        "        modelo.add(UpSampling2D())\n",
        "        modelo.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        modelo.add(BatchNormalization(momentum=0.8))\n",
        "        modelo.add(Activation(\"relu\"))\n",
        "        modelo.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "        modelo.add(Activation(\"tanh\"))\n",
        "\n",
        "        ruido = Input(shape=(self.dimensao_randomica,))\n",
        "        imagem_gerada = modelo(ruido)\n",
        "\n",
        "        return Model(ruido, imagem_gerada)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        modelo = Sequential()\n",
        "\n",
        "        modelo.add(Conv2D(32, kernel_size=3,strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        modelo.add(LeakyReLU(alpha=0.2))\n",
        "        modelo.add(Dropout(0.25))\n",
        "        modelo.add(Conv2D(64, kernel_size=3,strides=2, padding=\"same\"))\n",
        "        modelo.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        modelo.add(BatchNormalization(momentum=0.8))\n",
        "        modelo.add(LeakyReLU(alpha=0.2))\n",
        "        modelo.add(Dropout(0.25))\n",
        "        modelo.add(Conv2D(128, kernel_size=3,strides=2, padding=\"same\"))\n",
        "        modelo.add(BatchNormalization(momentum=0.8))\n",
        "        modelo.add(LeakyReLU(alpha=0.2))\n",
        "        modelo.add(Dropout(0.25))\n",
        "        modelo.add(Conv2D(256, kernel_size=3,strides=1, padding=\"same\"))\n",
        "        modelo.add(BatchNormalization(momentum=0.8))\n",
        "        modelo.add(LeakyReLU(alpha=0.2))\n",
        "        modelo.add(Dropout(0.25))\n",
        "        modelo.add(Flatten())\n",
        "        modelo.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        imagem_entrada = Input(shape=self.img_shape)\n",
        "        verificacao = modelo(imagem_entrada)\n",
        "\n",
        "        return Model(imagem_entrada, verificacao)\n",
        "    \n",
        "    def train(self, epochs, batch_size=128, intervalo_registro=50, x_treino=None):\n",
        "\n",
        "        x_treino = x_treino # carregando o dataset\n",
        "\n",
        "        # Criando os gabaritos (img reais = 1, imgs fake = 0)\n",
        "        uns = np.ones((batch_size,1))\n",
        "        zeros = np.zeros((batch_size,1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            \"Discriminator\"\n",
        "            # Selecionando um batch aleatório de imagens reais:\n",
        "            indices = np.random.randint(0, x_treino.shape[0],batch_size)\n",
        "            imagens_reais = x_treino[indices]\n",
        "\n",
        "            # Selecionando um batch de ruídos para gerar imagens fake:\n",
        "            amostras_ruidos = np.random.normal(0,1, (batch_size, self.dimensao_randomica))\n",
        "            imagens_geradas = self.generator.predict(amostras_ruidos)\n",
        "\n",
        "            # Treinando o discriminator para aprender a diferença entre imagens reais e fake:\n",
        "            d_loss_real = self.discriminator.train_on_batch(imagens_reais, uns)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(imagens_geradas, zeros)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            \"Generator\"\n",
        "            # Treinando o generator para aprender a enganar o discriminator:\n",
        "            generator_loss = self.gan_completa.train_on_batch(amostras_ruidos, uns)\n",
        "\n",
        "            # Mostrando o progresso:\n",
        "            print(f\"{epoch} [Discrimator loss: {discriminator_loss[0]}, Acurácia: {100*discriminator_loss[1]:.2f}] [Generator loss: {generator_loss}]\")\n",
        "\n",
        "            # Salvando as imagens geradas:\n",
        "            if epoch % intervalo_registro == 0:\n",
        "                self.save_imgs(epoch)\n",
        "    def save_imgs(self, epoch):\n",
        "        linhas = 5\n",
        "        colunas = 5\n",
        "        amostras_ruidos = np.random.normal(0, 1, (linhas * colunas, self.dimensao_randomica))\n",
        "        imagens_geradas = self.generator.predict(amostras_ruidos)\n",
        "\n",
        "        # Normalizando as imagens entre [0,1] para mostrar com o matplotlib gray:\n",
        "        imagens_geradas = 0.5 * imagens_geradas + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(linhas, colunas)\n",
        "        cont = 0\n",
        "        for i in range(linhas):\n",
        "            for j in range(colunas):\n",
        "                axs[i,j].imshow(imagens_geradas[cont,:,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cont +=1\n",
        "        fig.savefig(\"/content/drive/MyDrive/Colab Notebooks/mnist_%d.png\" % epoch)\n",
        "        plt.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djvz29jjQPVr"
      },
      "source": [
        "import time\n",
        "gan_convolucional = DCGAN()\n",
        "inicio = time.time()\n",
        "gan_convolucional.train(epochs=20000, batch_size=32, intervalo_registro=500, x_treino=x_treino)\n",
        "print(f\"Tempo em minutos: {(time.time() - inicio)/60}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}